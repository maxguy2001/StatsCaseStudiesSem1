---
title: "Dementia Risk Factors: EDA of easySHARE data"
author: "Katrina Sanders, Kim Johnston, Max Guy"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load data

Load the easySHARE data. For information on data and variables, see the [easySHARE data  guide](http://www.share-project.org/fileadmin/pdf_documentation/easySHARE_Release_8.0.0_ReleaseGuide.pdf).

```{r load_data}
load("../data/easySHARE_rel8_0_0.rda")
dat<-easySHARE_rel8_0_0
rm(easySHARE_rel8_0_0)
```

Load packages:
  
```{r load_libs, message = FALSE}
library(tidyverse)
library(gridExtra)
library(visdat)
library(StatCompLab)
```

## Pre-processing

## Cognitive score

EasySHARE does not record diagnosis of dementia (e.g. Alzheimer's disease) in all waves. Instead, we will create a composite cognitive score as a proxy for dementia severity, following [Crimmins et al. (2011)](https://pubmed.ncbi.nlm.nih.gov/21743047/). The cognitive function indices are described in pg. 23 of the easySHARE data guide.

```{r cogindices, message = FALSE, fig.height=3, fig.width=9}
#select relevant cognitive variables
cogvars <- c("recall_1", "recall_2", "orienti", "numeracy_1", "numeracy_2")

#select cognitive subset of dataframe
cog = dat[cogvars]

#make exploratory plots
p1 = ggplot() +
  geom_histogram(aes(x=cog$recall_1), color="darkblue", fill="lightblue") +
  labs(x ="Recall of words, first trial")
p2 = ggplot() +
  geom_histogram(aes(x=cog$recall_2), color="darkblue", fill="lightblue") +
  labs(x ="Recall of words, second trial")
p3 = ggplot() +
  geom_histogram(aes(x=cog$orienti), color="darkblue", fill="lightblue") +
  labs(x ="Orientation to date")
p4 = ggplot() +
  geom_histogram(aes(x=cog$numeracy_1), color="darkblue", fill="lightblue") +
  labs(x ="Numeracy Score 1 (percentage)")
p5 = ggplot() +
  geom_histogram(aes(x=cog$numeracy_2), color="darkblue", fill="lightblue") +
  labs(x ="Numeracy Score 2 (subtraction)")
grid.arrange(p1, p2, p3, p4, p5, nrow = 2)
rm(p1, p2, p3, p4, p5)
```

Notice the missing values (missing codes are explained on pg. 6 of missing codes of the easySHARE guide). In addition, for the numeracy measures, only one score is recorded in latter waves (pg. 23). Here we take a simple average if both measures are available. However, you may consider other approaches (please include an explanation/motivation). Notice that  `numeracy_1` ranges from 1 to 5, while `numeracy_2` ranges from 0 to 5.

```{r numeracy, message = FALSE, warning=FALSE, fig.height=2, fig.width=3}
#function to add numeracy column
add_numeracy <- function(cog){
  numeracy = rep(NA,dim(cog)[1])
  numeracy[cog$numeracy_1 >= 0 & cog$numeracy_2 >= 0] =      (cog$numeracy_1[cog$numeracy_1 >= 0 & cog$numeracy_2 >= 0] + cog$numeracy_2[cog$numeracy_1 >= 0 & cog$numeracy_2 >= 0] )/2
  numeracy[cog$numeracy_1 >= 0 & cog$numeracy_2 < 0] = cog$numeracy_1[cog$numeracy_1 >= 0 & cog$numeracy_2 < 0]
  numeracy[cog$numeracy_1 < 0 & cog$numeracy_2 >= 0] = cog$numeracy_2[cog$numeracy_1 < 0 & cog$numeracy_2 >= 0]
  cog$numeracy = numeracy
  return(cog)
}

#call function to add numeracy column
cog <- add_numeracy(cog)

#plot numeracy histogram
ggplot() +
  geom_histogram(aes(x=cog$numeracy), color="darkblue", fill="lightblue") +
  labs(x ="Numeracy Score")
```

We now create a composite cognitive score, ranging from 0 (bad) to 29 (good), that combines the recall scores, orientation, and numeracy measure. Note that orientation the description of the scale of orientation in the easySHARE guide appears incorrect, and I believe it should be 0 (bad) and 4 (good). 

```{r cogscore, message = FALSE, warning=FALSE, fig.height=2, fig.width=3}

#function to add cognitive score
add_cogscore <- function(cog){
  numeracy <- cog$numeracy
  cogscore = rep(NA,dim(cog)[1])
  ind <<- cog$recall_1 >= 0 & cog$recall_2 >= 0 & cog$orienti >= 0 & !is.na(numeracy)
  cogscore[ind] = cog$recall_1[ind] + cog$recall_2[ind] +  cog$orienti[ind] + cog$numeracy[ind]
  cog$cogscore = cogscore
return(cog)
}

#call function to add cognitive score
cog <- add_cogscore(cog)

#plot cognitive score histogram
ggplot() +
  geom_histogram(aes(x=cog$cogscore[ind]), color="darkblue", fill="lightblue", binwidth =2 ) +
  labs(x ="Composite cogntive score")

dat$cogscore<-cog$cogscore
```


## Dementia risk factors

Extract variables related to modifiable risk factors identified in literature: education, hearing loss, traumatic brain injury, hypertension, alcohol consumption, smoking, obesity, physical activity, depression, social isolation, diabetes, and air pollution [Livingston et al. (2020)](https://www.thelancet.com/article/S0140-6736(20)30367-6/fulltext). Refer to the easySHARE guide for a description of the variables availble. You may also consider other relevant risk factors, along with an explanation and motivation. Gender and age are also relevant variables to consider, e.g. to explore differences between men and women [Beam et al. (2018)](https://pubmed.ncbi.nlm.nih.gov/30010124/).


```{r filtering_df}
#set appropriate na values
dat[dat < 0 ] <- NA

dat$everyday_tasks <- dat$adla + dat$iadlza

dat$diabetes <- dat$chronic_mod
dat$hypertension <- dat$chronic_mod

# adding hypertension and diabetes to the variables
dat$diabetes[dat$diabetes != 5] <- 0
dat$diabetes[dat$diabetes == 5] <- 1
dat$hypertension[dat$hypertension != 2] <- 0
dat$hypertension[dat$hypertension == 2] <- 1
dat$ever_smoked[dat$ever_smoked == 5] <- 0

#filter subset of dataframe
df <- dat %>%
  filter(country == 35) %>%
  filter(wave == 4)

# removing variables we don't want or have too many NAs

df_columns <- df[,(names(df) %in% c("female", "age", "sphus", "isced1997_r", "eduyears_mod", "hhsize", "euro5", "eurod", "hypertension", "br010_mod", "bmi", "ever_smoked", "br015_", "mobilityind", "diabetes", "everyday_tasks", "cogscore"))]

# now remove the ones that are part of cognitive score
df_columns <- df_columns[,!(names(df_columns) %in% c( "numeracy_1", "numeracy_2", "orienti", "recall_1", "recall_2"))]

colSums(is.na(df_columns))

# count number of usable rows
nrow(df_columns %>% drop_na())

#remove incomplete rows from dataframe
df_final <- na.omit(df_columns)

```

## Exploring data, stats:


When first looking at the data, we wanted to clearly be able to see if there was any problematic data we would have to deal with. This shows the amount of NAs and so from here we are able to look at the mostly NA columns closer to decide if they need to be kept in to further our investigation.
```{r vis_dat}
vis_dat(df)
```
From this plot we saw that no variable we planned to include from the Lancet report had a large number of missing values, therefore we didn't need to make any changes to our choice of variables.

Instincts suggest that $mother\_alive$ and $father\_alive$ may confound with age, as the older you get the older your parents also become so there is more chance that older individuals have fewer parents still alive. After exploring this relationship this, it clearly shows, as expected, that the mean age of those with their mother still alive is lower than for those where their mother is no longer alive.
```{r mother_alive}
label=c("Yes","No")
boxplot(df$age ~ df$mother_alive, 
        data = df, 
        main="Corelation between Age and Mother Alive", 
        xlab= "age", 
        ylab= "mother_alive",
        names = label)

```

Then looking at the relationship between $father\_alive$ and age it is clear that again the proportion of those with their father still alive is greater for the younger age group. Therefore, both $mother\_ alive$ and $father\_alive$ are seen to confound with $age$.

```{r proportion_father_alive}
plot(prop.table(xtabs(~ (round(age)>60) +father_alive, df),2), 
     main="Proportion of Age >60, of Father Alive", 
     xlab="age > 60", 
     col=c("forestgreen", "dodgerblue"))

```

By this simple histogram it is clear that all those who participated were adults, as none were under 25. We can then say that cognitive score once calculated isn't affected by an individual being too young, causing cognitive score to be lower due to their brain not being fully developed. Hence, concluding that when looking at predicting dementia it won't be skewed by younger individuals.

```{r hist_of_ages}

barplot(table(round(df_final$age)), 
        main="Histogram of Ages", 
        col = "forestgreen")

```


Each level of $chronic\_mod$ is a different disease, and from this plot we can see that the distribution of ages with each of these diseases is higher than the overall population distribution. This suggests there may be a relationship between the two variables, and $chronic\_mod$ may in fact confound with $age$.

```{r age_chronic_mod}
label2=c("Heart attack","Hypertension", "High Blood", "Stroke", "Diabetes", "Chronic Lung Disease", "Asmtha", "Arthritis", "Cancer")
boxplot(df$age ~ df$chronic_mod, 
        data = df, 
        main="Corelation between Age and Chronic Disease", 
        xlab= "age", 
        ylab= "chronic_mod",
        names = label2)

```


This graph shows there appears to be a a pattern between those who have smoked and the age of participants,  particularly the older participants. This may suggest that smoking has some impact on life expectancy but would need further investigation.

```{r}

boxplot(round(df_final$age) ~ df_final$ever_smoked, 
        data = df_final, 
        main="Correlation between Age and Smoking", 
        xlab= "ever_smoked", 
        ylab= "age")


```


Now looking specifically at the cognitive score, we can look into how age compares with cognitive score. It is clear that as age decreases cognitive score does too, which is intuitive from previous investigation however can be seen clearly with the red line.
```{r cogscore_age}
ggplot(df_final, aes(x=age, y=cogscore)) +
  geom_point(alpha=0.2) + 
  geom_smooth(method="lm", se=FALSE, color = "red", formula=y~x)

```

The box plot shows that as self-perceived health decreases as cognitive score decreases, showing that cognitive score is affected by one's perception of their own health, so can be used as a predictor to look into further.

```{r self_health}

boxplot(round(df_final$cogscore) ~ round(df_final$sphus) , 
        data = df_final, 
        main="Correlation between Cognitive score and self-percieved health", 
        xlab= "sphus", 
        ylab= "cogscore")
```


Looking at the box plot between education level reached and cognitive score, we can see that there is a clear relationship between these variables. As education level reached increases, cognitive score also increases and therefore may be a good predictor of $cogscore$ to use in our model.
```{r education_trend}
boxplot(round(df_final$cogscore) ~ round(df_final$isced1997_r) , 
        data = df_final, 
        main="Correlation between Cognitive score and Level of education acheived", 
        xlab= "isced1997_r", 
        ylab= "cogscore")

```


## Creating a model


```{r model_seup}
set.seed(567)

train_index <- sample(1:nrow(df_final), size =200)

df_test <- df_final[train_index, ]
df_train <- df_final[-train_index,]

#check there is no overlap between data sets
dplyr::intersect(df_train, df_test) 
```


```{r construct_model}
lm <- lm(cogscore ~ ., data = df_train)
summary(lm)

lm1 <- lm(cogscore ~ age*(female + age + isced1997_r + eduyears_mod + hhsize + 
    sphus + euro5 + eurod + mobilityind + bmi + ever_smoked + br010_mod + br015_ + diabetes + 
    hypertension + everyday_tasks), data = df_train)  

summary(lm1)

```

```{r update_model_1}

model<-step(lm1, trace=F, k=log(nrow(df_train))) # BIC, Bayesian Information criterion. This penalises more for large sample size. Hence we end up with a smaller model.
summary(model)
formula(model)
plot(model)

vars <- c("cogscore", "female", "age", "isced1997_r", "eduyears_mod", "sphus", "euro5", "eurod", "br015_", "everyday_tasks" )
```

```{r bic_interactions}
model_interactions<-step(lm1, trace=F, k=log(nrow(df_train))) 
summary(model_interactions)
formula(model_interactions)
plot(model_interactions)
```



```{r upate_model_2}
new_model <- lm(cogscore ~ age*(female + age + isced1997_r + eduyears_mod + euro5 + 
    eurod + everyday_tasks ), data = df_train)

new_model<-step(new_model, trace=F, k=log(nrow(df_train))) # BIC, Bayesian Information criterion. This penalises more for large sample size. Hence we end up with a smaller model.
summary(new_model)
formula(new_model)
plot(new_model)
```

```{r baseline_model}

model_age <- lm(cogscore ~ age, data = df_train)

summary(model_age)
formula(model_age)
plot(model_age)
```

```{r getting_rmse}
# residual sum of squares 
RSS <- c(crossprod(model$residuals))
RSS_new <- c(crossprod(new_model$residuals))
RSS_interactions <- c(crossprod(model_interactions$residuals))
RSS_age <- c(crossprod(model_age$residuals))

# mean square error
MSE <- RSS/length(model$residuals)
MSE_new <- RSS_new/length(new_model$residuals)
MSE_interactions <- RSS_interactions/length(model_interactions$residuals)
MSE_age <- RSS_age/length(model_age$residuals)

# root mean square error
RMSE <- sqrt(MSE)
RMSE_new <- sqrt(MSE_new)
RMSE_interactions <- sqrt(MSE_interactions)
RMSE_age <- sqrt(MSE_age)

```


```{r producing_ci}
# to include in table
coefs<-model_interactions$coefficients 
CI<- confint(model_interactions) 
print(CI)

coef_confint <- cbind(coefs, CI) %>% as.data.frame()
coef_confint <- coef_confint %>% mutate(variable=rownames(coef_confint))
library(plyr) 
coef_confint <- rename(coef_confint,c("coefs" = "Coefficients",
                                      `2.5 %` = "lower_bound", 
                                      `97.5 %` = "upper_bound"))
coef_confint <- coef_confint %>% 
  mutate_if(is.numeric, round, digits = 2) 
plot_lm <- coef_confint[-1,] %>%  #remove row number 1 (The intercept) 
  ggplot(aes(x=reorder(variable, Coefficients), y=Coefficients)) +
  geom_point(shape = 15,
             size  = 4,
             position = "dodge", color="black") + 
  geom_errorbar(aes(ymin  = lower_bound,
                    ymax  = upper_bound),
                size  = 1,
                position = "dodge", color="turquoise4") +
  theme(axis.title = element_text(face = "bold")) +
  xlab("Variables") + ylab("Coeffecients with 95% CI") +
  coord_flip(ylim = c(-1.5, 1.4)) + 
  geom_hline(yintercept = 0, color = "red", size = 1) +
   theme(axis.title = element_text(size = 17)) + 
  theme(axis.text = element_text(size = 14)) 
show(plot_lm)

```


```{r linear-model-plot}
predicted <- fitted(model_interactions)

plot_dataframe <- data.frame(predicted, df_train$cogscore)

ggplot(plot_dataframe, aes(x = predicted, y = df_train$cogscore)) +
  geom_point() +
  stat_smooth() +
  xlab('prediction variables') +
  ylab('cognitive score')+
  labs(title = 'Linear Model Plot')

```

# Validation
```{r sorting-dataframes}

vars <- c("age", "female", "isced1997_r", "eduyears_mod", "sphus", "euro5", "eurod", "br010_mod", "br015_", "everyday_tasks", "age:br010_mod", "cogscore")

df_train_validation <- df_train[, names(df_train) %in% vars]
df_test_validation <- df_test[, names(df_test) %in% vars]

df_w4_c28 <- dat %>%
  filter(country == 28) %>%
  filter(wave == 4)

df_w5_c35 <- dat %>%
  filter(country == 35) %>%
  filter(wave == 5)

df_w5_c35 <- df_w5_c35[, names(df_w5_c35) %in% vars]
df_w4_c28 <- df_w4_c28[, names(df_w4_c28) %in% vars]

# count unusable rows
nrow(df_w5_c35 %>% drop_na())
nrow(df_w4_c28 %>% drop_na())

# drop unusable rows
df_w5_c35 <- na.omit(df_w5_c35)
df_w4_c28 <- na.omit(df_w4_c28)

```


```{r plotting_differences}
p_train <- data.frame(actual = df_train$cogscore, predicted = predict(model_interactions))
head(p_train)
plot(p_train$actual, p_train$predicted)
```


```{r validation_test}

getRMSE <- function(df, model){
  p_test <- predict(model, df)
  error_test <- p_test - df$cogscore
  RMSE_test <- sqrt(mean(error_test^2))
  
  plot(error_test)
  return(RMSE_test)
}

rmse_test_validation <- getRMSE(df_test_validation, model_interactions)

rmse_w5_c35 <- getRMSE(df_w5_c35, model_interactions)
  
rmse_w4_c28 <- getRMSE(df_w4_c28, model_interactions)

```

```{r show_rmse_results}
print(rmse_test_validation)
print(rmse_w4_c28)
print(rmse_w5_c35)

```


##Predictions - scoring
This is taken from Statistical Computing:
```{r scoring}
library(StatCompLab)

mean <-mean(df_final$cogscore)
sd <- sd(df_final$cogscore)
lwr <- mean - sd * qnorm(0.9)
upr <- mean - sd * qnorm(0.1)

#proper score is defined in statcomplab
score_A <- cbind(RMSE, df_train) %>%
  mutate(
    se = proper_score("se", cogscore, mean = mean(cogscore)),
    ds = proper_score("ds", cogscore, mean = mean(cogscore), sd = sd(cogscore)),
    interval = proper_score("interval", cogscore,
                            lwr = lwr, upr = upr, alpha = 0.1)
  )

score_A_table <-
  rbind(cbind(score_A, model = "A")) %>%
  group_by(model) %>%
          summarise(se = mean(se),
                    ds = mean(ds),
                    interval = mean(interval))
knitr::kable(score_A_table)
```


```{r scoring}
pred_real <- predict(model, newdata = df_final)
pred_base <- predict(model_interactions, newdata = df_train)
mean <-mean(df_final$cogscore)
sd <- sd(df_final$cogscore)
lwr1 <- mean - sd * qnorm(0.9)
upr1 <- mean - sd * qnorm(0.1)


score_real <- cbind(pred_real, df_final) %>%
  mutate(
    se = proper_score("se", cogscore, mean = mean),
    ds = proper_score("ds", cogscore, mean = mean, sd = sd),
    interval = proper_score("interval", cogscore,
                            lwr = lwr, upr = upr, alpha = 0.1)
  )
score_base <- cbind(pred_base, df_train) %>%
  mutate(
    se = proper_score("se", cogscore, mean = mean),
    ds = proper_score("ds", cogscore, mean = mean, sd = sd),
    interval = proper_score("interval", cogscore,
                            lwr = lwr, upr = upr, alpha = 0.1)
  )

score_real
score_base

```




