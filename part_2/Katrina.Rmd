---
title: "Dementia Risk Factors: EDA of easySHARE data"
author: "Katrina Sanders"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load data

Load the easySHARE data. For information on data and variables, see the [easySHARE data  guide](http://www.share-project.org/fileadmin/pdf_documentation/easySHARE_Release_8.0.0_ReleaseGuide.pdf).

```{r easyshare}
load("../data/easySHARE_rel8_0_0.rda")
dat<-easySHARE_rel8_0_0
```

Load packages:
  
```{r packs, message = FALSE}
library(ggplot2)
library(tidyverse)
library(gridExtra)
```

## Pre-processing

## Cognitive score

EasySHARE does not record diagnosis of dementia (e.g. Alzheimer's disease) in all waves. Instead, we will create a composite cognitive score as a proxy for dementia severity, following [Crimmins et al. (2011)](https://pubmed.ncbi.nlm.nih.gov/21743047/). The cognitive function indices are described in pg. 23 of the easySHARE data guide.

```{r cogindices, message = FALSE, fig.height=3, fig.width=9}

cogvars <- c("recall_1", "recall_2", "orienti", "numeracy_1", "numeracy_2")
cog = dat[cogvars]
p1 = ggplot() +
  geom_histogram(aes(x=cog$recall_1), color="darkblue", fill="lightblue") +
  labs(x ="Recall of words, first trial")
p2 = ggplot() +
  geom_histogram(aes(x=cog$recall_2), color="darkblue", fill="lightblue") +
  labs(x ="Recall of words, second trial")
p3 = ggplot() +
  geom_histogram(aes(x=cog$orienti), color="darkblue", fill="lightblue") +
  labs(x ="Orientation to date")
p4 = ggplot() +
  geom_histogram(aes(x=cog$numeracy_1), color="darkblue", fill="lightblue") +
  labs(x ="Numeracy Score 1 (percentage)")
p5 = ggplot() +
  geom_histogram(aes(x=cog$numeracy_2), color="darkblue", fill="lightblue") +
  labs(x ="Numeracy Score 2 (subtraction)")
grid.arrange(p1, p2, p3, p4, p5, nrow = 2)
```

Notice the missing values (missing codes are explained on pg. 6 of missing codes of the easySHARE guide). In addition, for the numeracy measures, only one score is recorded in latter waves (pg. 23). Here we take a simple average if both measures are available. However, you may consider other approaches (please include an explanation/motivation). Notice that  `numeracy_1` ranges from 1 to 5, while `numeracy_2` ranges from 0 to 5.

```{r numeracy, message = FALSE, warning=FALSE, fig.height=2, fig.width=3}
numeracy = rep(NA,dim(cog)[1])
numeracy[cog$numeracy_1 >= 0 & cog$numeracy_2 >= 0] = (cog$numeracy_1[cog$numeracy_1 >= 0 & cog$numeracy_2 >= 0] + cog$numeracy_2[cog$numeracy_1 >= 0 & cog$numeracy_2 >= 0] )/2
numeracy[cog$numeracy_1 >= 0 & cog$numeracy_2 < 0] = cog$numeracy_1[cog$numeracy_1 >= 0 & cog$numeracy_2 < 0]
numeracy[cog$numeracy_1 < 0 & cog$numeracy_2 >= 0] = cog$numeracy_2[cog$numeracy_1 < 0 & cog$numeracy_2 >= 0]
cog$numeracy = numeracy
ggplot() +
  geom_histogram(aes(x=cog$numeracy), color="darkblue", fill="lightblue") +
  labs(x ="Numeracy Score")
```

We now create a composite cognitive score, ranging from 0 (bad) to 29 (good), that combines the recall scores, orientation, and numeracy measure. Note that orientation the description of the scale of orientation in the easySHARE guide appears incorrect, and I believe it should be 0 (bad) and 4 (good). 

```{r cogscore, message = FALSE, warning=FALSE, fig.height=2, fig.width=3}
cogscore = rep(NA,dim(cog)[1])
ind = cog$recall_1 >= 0 & cog$recall_2 >= 0 & cog$orienti >= 0 & !is.na(numeracy)
cogscore[ind] = cog$recall_1[ind] + cog$recall_2[ind] +  cog$orienti[ind] + cog$numeracy[ind]
cog$cogscore = cogscore
ggplot() +
  geom_histogram(aes(x=cog$cogscore[ind]), color="darkblue", fill="lightblue", binwidth =2 ) +
  labs(x ="Composite cogntive score")

dat$cogscore<-cog$cogscore
```


## Dementia risk factors

Extract variables related to modifiable risk factors identified in literature: education, hearing loss, traumatic brain injury, hypertension, alcohol consumption, smoking, obesity, physical activity, depression, social isolation, diabetes, and air pollution [Livingston et al. (2020)](https://www.thelancet.com/article/S0140-6736(20)30367-6/fulltext). Refer to the easySHARE guide for a description of the variables availble. You may also consider other relevant risk factors, along with an explanation and motivation. Gender and age are also relevant variables to consider, e.g. to explore differences between men and women [Beam et al. (2018)](https://pubmed.ncbi.nlm.nih.gov/30010124/).


```{r}
dat_country_35 <- dat[dat$country == 35,]

df <- dat_country_35[dat_country_35$wave == 4,]

df[df < 0 ] <- NA

#colSums(is.na(df))

# removing variables we don't want or have too many NAs
df_remove_na_columns <- df[,!(names(df) %in% c( "mergeid", "hhid", "wave", "wavepart", "int_version", "int_year", "int_month", "country", "country_mod", "language", 
                                                "birth_country", "citizenship", "mar_stat", "partnerinhh", 
                                                "ch001_", "ch007_km", "casp", "sp002_mod", "adlwa", "iadla", "bmi2", 
                                                "co007_", "thinc_m",
                                                
                                                "dn002_mod", "dn003_mod", "dn004_mod",
                                                
                                                "euro1", "euro2", "euro3", "euro4", "euro6", "euro7", "euro8", 
                                                "euro9", "euro10", "euro11", "euro12", 
                                                "coupleid", "iv009_mod",
                                                "books_age10", "maths_age10", "language_age10", 
                                               "vaccinated", "childhood_health", "q34_re",
                                               "ch021_mod", "ch007_hh", "maxgrip",
                                               "int_partner", "age_partner", "gender_partner", "mother_alive", "father_alive", "siblings_alive",
                                               "sp003_1_mod", "sp003_2_mod",  "sp009_3_mod", "sp003_3_mod", "sp009_1_mod", "sp009_2_mod", "sp008_",
                                               "bfi10_extra_mod", "bfi10_agree_mod", "bfi10_consc_mod", "bfi10_neuro_mod", "bfi10_open_mod", 
                                               "ep005_", "ep009_mod", "ep011_mod", "ep013_mod", "ep026_mod", "ep036_mod",
                                               "income_pct_w1","income_pct_w2", "income_pct_w4","income_pct_w5", "income_pct_w6","income_pct_w7","income_pct_w8"))]

# now remove the ones that are part of cognitive score
df_remove_na_columns <- df_remove_na_columns[,!(names(df_remove_na_columns) %in% c( "numeracy_1", "numeracy_2", "orienti", "recall_1", "recall_2"))]

colSums(is.na(df_remove_na_columns))

# count number of usable rows
nrow(df_remove_na_columns %>% drop_na())

ncol(df_remove_na_columns)

df_remove_na_columns$diabetes <- df_remove_na_columns$chronic_mod
df_remove_na_columns$hypertension <- df_remove_na_columns$chronic_mod

# adding hypertension and diabetes to the variables
df_remove_na_columns$diabetes[df_remove_na_columns$diabetes != 5] <- 0
df_remove_na_columns$diabetes[df_remove_na_columns$diabetes == 5] <- 1
df_remove_na_columns$hypertension[df_remove_na_columns$hypertension != 2] <- 0
df_remove_na_columns$hypertension[df_remove_na_columns$hypertension == 2] <- 1

# remove chronic_mod as only interested in diabetes and hypertension
df_remove_na_columns <- df_remove_na_columns[,!(names(df_remove_na_columns)) %in% c("chronic_mod")] 
```

female
age
isced1997_r
eduyears_mod
hhsize
ch007_km
sphus
chronic_mod
casp
euro5
eurod
hc002_mod
hc012_
hc029_
adla
iadlza
mobilityind
lgmuscle
grossmotor
finemotor
bmi
smoking
ever_smoked
br010_mod
br015_
income_pct_w4


## Creating a model

3 different ways, all the same answer:
1. using step() which automatically sorts it
2. looking at summary and systematically removing each variable 
3. using step() but forward selection

All end up with same 14 predictors, but step 2. removes two extra which have 0.05 < p-values < 0.1

```{r}
df_final <- na.omit(df_remove_na_columns)

df_final$hc012_[df_final$hc012_ == 5] <- 0
df_final$hc029_[df_final$hc029_ == 5] <- 0
df_final$hc029_[df_final$hc029_ == 3] <- 1


```

```{r}
set.seed(567)

train_index <- sample(1:nrow(df_final), size =200)

df_test <- df_final[train_index, ]
df_train <- df_final[-train_index,]

#check there is no intercept
dplyr::intersect(df_train, df_test) 
```

```{r}
# step by step removal 

#summary(lm(cogscore ~ ., data = df_train))
#summary(lm(cogscore ~ . - finemotor - br010_mod - grossmotor - hc029_ - hypertension - hhsize - mobilityind - adla - lgmuscle - hc012_ - diabetes, data = df_train))

# now looking to see if removing smoking improves r^2 from 0.3673 - doesn't, decreases to 3.67
#summary(lm(cogscore ~ . - finemotor - br010_mod - grossmotor - hc029_ - hypertension - hhsize - mobilityind - adla - lgmuscle - hc012_ - diabetes - smoking, data = df_train))

# now looking to see if removing bmi improves r^2 from 0.3673 - doesn't, decreases to 3.67
#summary(lm(cogscore ~ . - finemotor - br010_mod - grossmotor - hc029_ - hypertension - hhsize - mobilityind - adla - lgmuscle - hc012_ - diabetes - bmi , data = df_train))

#keep both in, and this is the final model

summary(lm(cogscore ~ . - finemotor - br010_mod - grossmotor - hc029_ - hypertension - hhsize - mobilityind - adla - lgmuscle - hc012_ - diabetes, data = df_train))
```



Note backwards produces different model
```{r}
#formula(lm)
ggplot(df_train, aes(x = female - 0.12* age + 0.65*isced1997_r + 0.15*eduyears_mod - 0.23*sphus + 0.48*euro5 - 0.28*eurod + 0.011*hc002_mod + 0.015*bmi + 0.060*smoking - 0.085*ever_smoked - 0.17*br015_ , y = cogscore)) +
  geom_point() +
  stat_smooth()
```

```{r}
# residual sum of squares 
RSS <- c(crossprod(forward$residuals))

# mean square error
MSE <- RSS/length(forward$residuals)

# root mean sqaure error
RMSE <- sqrt(MSE)

print(RMSE)
```
Low RMSE is good 

# Validation
```{r sorting-dataframes}

variables <- c("age","isced1997_r", "iadlza", "eurod",  "female" , "br015_" , "eduyears_mod" , "euro5" , "sphus" , "chronic_mod" , "casp" , "bmi" , "ever_smoked", "cogscore")

df_train_validation <- df_train[, names(df_train) %in% variables]
df_test_validation <- df_test[, names(df_test) %in% variables]

dat_country_28 <- dat[dat$country == 28,]
df_w4_c28 <- dat_country_28[dat_country_28$wave == 4,]

df_w6_c35 <- dat_country_35[dat_country_35$wave == 6,]

df_w6_c35[df_w6_c35 < 0 ] <- NA
df_w4_c28[df_w4_c28 < 0 ] <- NA

df_w6_c35 <- df_w6_c35[, names(df_w6_c35) %in% variables]
df_w4_c28 <- df_w4_c28[, names(df_w4_c28) %in% variables]

# count unusable rows
nrow(df_w6_c35 %>% drop_na())
nrow(df_w4_c28 %>% drop_na())

# drop unusable rows
df_w6_c35 <- na.omit(df_w6_c35)
df_w4_c28 <- na.omit(df_w4_c28)

```


```{r validation}

```











